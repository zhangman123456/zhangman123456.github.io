<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>梯度下降法 | 张曼</title>
<link rel="shortcut icon" href="https://zhangman123456.github.io/favicon.ico?v=1594457217303">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://zhangman123456.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="梯度下降法 | 张曼 - Atom Feed" href="https://zhangman123456.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="#基本思想
假设我们爬山，如果想最快的上到山顶，那么我们应该从山势最陡的地方上山。也就是山势变化最快的地方上山
同样，如果从任意一点出发，需要最快搜索到函数最大值，那么我们也应该从函数变化最快的方向搜索。
函数变化最快的方向是什么呢？函数的..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://zhangman123456.github.io">
  <img class="avatar" src="https://zhangman123456.github.io/images/avatar.png?v=1594457217303" alt="">
  </a>
  <h1 class="site-title">
    张曼
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              梯度下降法
            </h2>
            <div class="post-info">
              <span>
                2020-07-11
              </span>
              <span>
                7 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>#基本思想<br>
假设我们爬山，如果想最快的上到山顶，那么我们应该从山势最陡的地方上山。也就是山势变化最快的地方上山<br>
同样，如果从任意一点出发，需要最快搜索到函数最大值，那么我们也应该从函数变化最快的方向搜索。<br>
函数变化最快的方向是什么呢？函数的<strong>梯度</strong>。<br>
假如函数为一元函数，<strong>梯度</strong>就是该函数的倒数<img src="https://zhangman123456.github.io/post-images/1594430603494.png" alt="" loading="lazy"><br>
如果为二元函数，梯度定义为：<img src="https://zhangman123456.github.io/post-images/1594430651348.png" alt="" loading="lazy">（此处用到高数偏导数的知识来求二元函数的倒数）<br>
如果需要找的是函数极小点，那么应该从负梯度的方向寻找，该方法称之为梯度下降法。<br>
<img src="https://zhangman123456.github.io/post-images/1594430871728.png" alt="" loading="lazy">要搜索极小值C点，在A点必须向x增加方向搜索，此时与A点梯度方向相反；在B点必须向x减小方向搜索，此时与B点梯度方向相反。总之，搜索极小值，必须向负梯度方向搜索。<br>
假设函数 y = f(x1,x2,......,xn) 只有一个极小点。初始给定参数为  X0 = (x10,x20,......xn0) 从这个点如何搜索才能找到原函数的极小值点？<br>
方法：</p>
<ol>
<li>首先设定一个较小的正数η，ε;</li>
<li>求当前位置处的各个偏导数：<img src="https://zhangman123456.github.io/post-images/1594431281163.png" alt="" loading="lazy"></li>
<li>修改当前函数的参数值，公式如下：<br>
<img src="https://zhangman123456.github.io/post-images/1594431327433.png" alt="" loading="lazy"></li>
<li>如果参数变化量小于，退出；否则返回2。<br>
例：任给一个初始出发点，设为x0=-4，利用梯度下降法求函数y=x²/2-2x的极小值。<br>
准备工作：<br>
（1）给定两个参数值η = 0.9，ε = 0.01（η即为学习效率，或者步长）<br>
（2）计算导数：dy/dx = x - 2;<br>
一.（1）计算当前导数值：y' = -4 - 2 = -6；<br>
   （2）修改当前的参数值：x = x-ηy' = -4 - 0.9*(-6) = 1.4;<br>
  （3）计算△x = -0.9 * （-6）= 5.4。<br>
  （4）将△x与ε进行比较，如果△x&lt;=ε ，则变化量满足终止条件，终止循环，输出参数x；<br>
              如果△x&gt;ε，则继续进行循环<br>
              通过比较，可知△x&gt;ε，继续进行循环<br>
二.（1）计算当前导数值：y' = 1.4 - 2 = -0.6；<br>
   （2）修改当前的参数值：x = x-ηy' = 1.4 - 0.9*(-0.6)= 1.94;<br>
  （3）计算△x = -0.9 * （-0.6）= 0.54。<br>
  （4）将△x与ε进行比较，如果△x&lt;=ε ，则变化量满足终止条件，终止循环，输出参数x；<br>
              如果△x&gt;ε，则继续进行循环<br>
              通过比较，可知△x&gt;ε，继续进行循环。<br>
三.（1）计算当前导数值：y' = 1.94 - 2 = -0.06；<br>
   （2）修改当前的参数值：x = x-ηy' = 1.94 - 0.9*(-0.06)= 1.994;<br>
  （3）计算△x = -0.9 * （-0.06）= 0.054。<br>
  （4）将△x与ε进行比较，如果△x&lt;=ε ，则变化量满足终止条件，终止循环，输出参数x；<br>
              如果△x&gt;ε，则继续进行循环<br>
              通过比较，可知△x&gt;ε，继续进行循环。<br>
四.（1）计算当前导数值：y' = 1.994 - 2 = -0.006；<br>
   （2）修改当前的参数值：x = x-ηy' = 1.994 - 0.9*(-0.006)= 1.9994;<br>
  （3）计算△x = -0.9 * （-0.006）= 0.0054。<br>
  （4）将△x与ε进行比较，如果△x&lt;=ε ，则变化量满足终止条件，终止循环，输出参数x；<br>
              如果△x&gt;ε，则继续进行循环<br>
              通过比较，可知△x&lt;=ε，则终止循环，输出此时的x即为函数的极小点。<br>
python代码实现</li>
</ol>
<pre><code class="language-python">＃解决实例的Python代码
import numpy as np
inport matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rcParams['font.family'] = 'sans-serif'
mpl.rcParams['font.sans-serif'] = 'SimHei'
mpl.rcParams['axes.unicode_minus'] = false

#构建一维元素图形
def f1(x):
　　return 0.5 * (x ** 2) - 2x
def h1(x):
　　return x-2

#使用梯度下降法
GD_X = []
GD_Y = []
x = -4
alpha = 0.9
f_change = np.abs(alpha * hl(x))
f_current = f_change
GD_X.append(x)
GD_Y.append(f_current)

#迭代次数
iter_num = 0
while f_change &gt;0.01 and iter_num&lt;10:
　　iter_num+=1
　　x = x - x - alpha * h1(x)
　　tem = f1(x)
　　f_change = np.abs(alpha * hl(x))
　　f_current = tmp
　　GD_X.append(f_current)

print(u'最终的结果：(%.5f,%.5f)'%(x,f_current))
pirnt(u'迭代次数：%d'%iter_num)
printf(GD_X)
</code></pre>
<p>#损失函数<br>
学习了梯度下降之后，我们引入新的概念：<strong>损失函数</strong>。便于我们直接利用梯度下降法计算损失函数的最小值。<br>
我们可以近似地将<strong>损失函数</strong>理解为方差或者平方差。根据给出的一系类数据我们可以得出相关的函数，再根据该函数和不同变量，我们可以得出不同变量对应的不同的函数值。而每个函数值和每个真实的数值之间有一定的误差，根据这些误差我们可以得到相关的函数，即<strong>损失函数</strong>。<strong>损失函数</strong>的值越小，我们之前得到的函数就越精确。<br>
例：根据某组数据得到预测的函数：h(x) = θ₁ + θ₂x。只含有一个特征/输入变量。在这个式子中θ₁，θ₂都是未知参数，x是已知数据。我们的目的是得到合适的参数使得我们的预测尽可能准确。这时就需要引入损失函数的概念。<br>
<img src="https://zhangman123456.github.io/post-images/1594383086368.jpg" alt="" loading="lazy"><em>(暂时不用管1/2)</em><br>
上图中的J(θ₁,θ₂)是一个关于θ₁和θ₂的二元函数，也就是<strong>损失函数</strong>。在三维空间坐标系内，存在一对点（θ₁,θ₂）使得J(θ₁,θ₂)有最小值<br>
然后对损失函数进行一个简单的推导（利用梯度下降的算法）<br>
<img src="https://zhangman123456.github.io/post-images/1594444209052.jpg" alt="" loading="lazy"><br>
#梯度下降法的三个变种<br>
了解了梯度下降法的核心思想以及损失函数后，我们接着了解梯度下降法的三个变种<br>
1.批量梯度下降法（BGD）<br>
其需要计算整个训练集的梯度，即：<img src="https://i.loli.net/2019/08/12/zAiXFLUSyrd5qap.png" alt="" loading="lazy">其中η为学习率，用来控制更新的“力度”/&quot;步长&quot;。<br>
优点：<br>
    对于凸目标函数，可以保证全局最优； 对于非凸目标函数，可以保证一个局部最优。<br>
2.随机梯度下降算法（SGD）<br>
仅计算某个样本的梯度，即针对某一个训练样本 xi及其label yi更新参数：<img src="https://i.loli.net/2019/08/12/ItgcSRaT4jreKMl.png" alt="" loading="lazy">逐步减小学习率，SGD表现得同BGD很相似，最后都可以有不错的收敛。<br>
优点：<br>
    更新频次快，优化速度更快; 可以在线优化(可以无法处理动态产生的新样本)；一定的随机性导致有几率跳出局部最优(随机性来自于用一个样本的梯度去代替整体样本的梯度)。<br>
3.小批量梯度下降算法(MBGD),计算包含n个样本的mini-batch的梯度：<img src="https://i.loli.net/2019/08/12/ItgcSRaT4jreKMl.png" alt="" loading="lazy">MBGD是训练神经网络最常用的优化方法。<br>
优点：<br>
参数更新时的动荡变小，收敛过程更稳定，降低收敛难度；可以利用现有的线性代数库高效的计算多个样本的梯度。</p>

              </div>
              <div class="toc-container">
                
              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://zhangman123456.github.io/post/hello-gridea/">
              <h3 class="post-title">
                Hello Gridea
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://zhangman123456.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
