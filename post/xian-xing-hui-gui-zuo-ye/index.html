<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>线性回归作业 | 张曼</title>
<link rel="shortcut icon" href="https://zhangman123456.github.io/favicon.ico?v=1595170165646">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://zhangman123456.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="线性回归作业 | 张曼 - Atom Feed" href="https://zhangman123456.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="1.该样本回归方程就是我我们需要拟合的曲线：
                     h(x) = θ0 + θ1x；
2.得出关于该回归方程的误差函数:
3.对误差函数求导：

4.之后更新的到的θ0 和 θ1
（公式里的α是学习率，我..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://zhangman123456.github.io">
  <img class="avatar" src="https://zhangman123456.github.io/images/avatar.png?v=1595170165646" alt="">
  </a>
  <h1 class="site-title">
    张曼
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              线性回归作业
            </h2>
            <div class="post-info">
              <span>
                2020-07-13
              </span>
              <span>
                4 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>1.该<u>样本回归方程</u>就是我我们需要拟合的曲线：<br>
                     <strong>h(x) = θ<sub>0</sub> + θ<sub>1</sub>x</strong>；<br>
2.得出关于该回归方程的误差函数:<img src="https://zhangman123456.github.io/post-images/1594575102477.gif" alt="" loading="lazy"><br>
3.对误差函数求导：<img src="https://zhangman123456.github.io/post-images/1594632959520.gif" alt="" loading="lazy"><br>
<img src="https://zhangman123456.github.io/post-images/1594575689326.gif" alt="" loading="lazy"><br>
4.之后更新的到的θ<sub>0</sub> 和 θ<sub>1</sub><img src="https://zhangman123456.github.io/post-images/1594632981086.gif" alt="" loading="lazy"><br>
<img src="https://zhangman123456.github.io/post-images/1594575337724.gif" alt="" loading="lazy">（公式里的α是学习率，我们可以象征性地理解为步长）<br>
5.接下来，利用梯度下降的方法。这里我们可以分别使用批量梯度下降和随机梯度下降的方法来实现**（有助于更加具体地理解这两种梯度下降的算法）**<br>
（1）批量梯度下降算法<img src="https://zhangman123456.github.io/post-images/1594577818861.png" alt="" loading="lazy"><u>（上标i代表具体的某一个数据；x<sub>j</sub>代表系数θ<sub>j</sub>对应的因变量）</u><br>
  每一次的迭代，都把从θ<sub>0</sub> 到 θ<sub>j</sub>的每一个参数进行迭代；而每一次对每一个参数进行迭代时，都需要把全部的样本都使用一遍，这样重复迭代直到θ<sub>j</sub>收敛为止。所以说该算法的复杂度是O(i（j+1）)<br>
（为了防止我忘了，我写了一个一看就懂的版本）<br>
  <img src="https://zhangman123456.github.io/post-images/1594579705255.jpg" alt="" loading="lazy"><br>
（2）随机梯度下降法<img src="https://zhangman123456.github.io/post-images/1594579776426.png" alt="" loading="lazy"><br>
  每一次的迭代，都把从θ<sub>0</sub> 到 θ<sub>j</sub>的每一个参数进行迭代；而每一次对每一个参数进行迭代时，只使用所有样本中的一个数据，一旦到达最大的迭代次数或是满足预期的精度，就停止。这样算法的复杂度为O(j+1)，就下降了很多。<br>
  <u>（还是一个一看就会的版本）</u><img src="https://zhangman123456.github.io/post-images/1594580748171.jpg" alt="" loading="lazy"></p>
<pre><code>#批量梯度下降
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
 
#数据
a = np.random.standard_normal((1, 500))
x = [150,200,250,300,350,400,600]#自变量x
y = [6450,7450,8450,9450,11450,15450,18450]#因变量y
y = y - a*10
y = y[0]
def Optimization(x,y,theta,learning_rate):
    for i in range(iter):#批量梯度下降算法的核心，iter是最大迭代的次数。
        theta = Updata(x,y,theta,learning_rate)更新参数用的函数
    return theta#这是全部迭代之后的最后一组参数值 
def Updata(x,y,theta,learning_rate):
    m = len(x)#因变量的长度，即每次迭代的次数
    sum = 0.0
    sum1 = 0.0
    alpha = learning_rate
    h = 0
    for i in range(m):#每一次迭代，都用到全部的样本数据
        h = theta[0] + theta[1] * x[i]#一元线性回归方程，即我们需要拟合的曲线。
        sum += (h - y[i])
        sum1 += (h - y[i]) * x[i]
    theta[0] -= alpha * sum / m #更新theta[0]
    theta[1] -= alpha * sum1 / m #更新theta[1]
    return theta#每一次迭代都输出更新后的参数
 
#数据初始化
learning_rate = 0.001#学习率
theta = [0,0]#最开始的参数值
iter = 1000#循环的次数
theta = Optimization(x,y,theta,learning_rate)
 
plt.rcParams['font.sans-serif']=['SimHei']#该函数用来定义图形的各种默认属性，比如字符显示，线条样式，窗口大小，坐标轴宽度等等属性
plt.rcParams['axes.unicode_minus'] = False
'''
plt.figure(figsize=(35,35))
plt.scatter(x,y,marker='o')
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
plt.xlabel('特征X',fontsize=40)
plt.ylabel('Y',fontsize=40)
plt.title('样本',fontsize=40)
plt.savefig(&quot;样本.jpg&quot;)
'''
#可视化
b = np.arange(0,50)
c = theta[0] + b * theta[1]
 
plt.figure(figsize=(35,35))
plt.scatter(x,y,marker='o')
plt.plot(b,c)
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
plt.xlabel('特征X',fontsize=40)
plt.ylabel('Y',fontsize=40)
plt.title('结果',fontsize=40)
plt.savefig(&quot;结果.jpg&quot;)
</code></pre>

              </div>
              <div class="toc-container">
                
              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://zhangman123456.github.io/post/xian-xing-hui-gui/">
              <h3 class="post-title">
                线性回归
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://zhangman123456.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
